# Executive Summary: AR-LVM Abandonment

**Date**: 2025-11-04
**Decision**: Abandon autoregressive vector LVM, pivot to retrieval-only vecRAG
**Evidence**: 8 failed training attempts + decisive narrative validation test

---

## TL;DR

**Attempted**: Train autoregressive model to predict next paragraph vector from 5 previous paragraph vectors.

**Embedding model**: GTR-T5-base (sentence transformer, 768D) used at **paragraph level** (not sentence level).

**Result after 2 months**: Margin consistently negative across all approaches (predicts backward, not forward).

**Root cause**: GTR-T5 embeddings (trained on masked language modeling) encode **semantic similarity** (symmetric), not **temporal causality** (asymmetric). This is true at both sentence AND paragraph scales.

**Decision**: Stop autoregressive LVM work. Focus on retrieval-only vecRAG (already works: 73.4% Contain@50).

---

## What We Tested

### Embedding Model
- **GTR-T5-base** (sentence-transformers/gtr-t5-base)
- 768-dimensional dense embeddings
- Trained on: Masked language modeling (bidirectional context)
- **Used at**: Paragraph level (not sentence level)
  - Each "chunk" = 1 paragraph from source documents
  - Sliding window: 5 paragraphs of context â†’ predict 6th paragraph

### Task
- **Autoregressive next-chunk prediction**: Given vectors [vâ‚, vâ‚‚, vâ‚ƒ, vâ‚„, vâ‚…], predict vâ‚†
- **Evaluation metric**: Margin = cos(pred, vâ‚†) - cos(pred, vâ‚…)
- **Success criteria**: Positive margin (pred more similar to next than to previous)

### 8 Training Attempts (P1-P8)

| Approach | Architecture | Key Innovation | Margin | Result |
|----------|--------------|----------------|--------|--------|
| P1 | Transformer | Baseline MSE | -0.167 | Follows backward signal |
| P2-P4 | LSTM/Transformer | Directional margin loss | Negative | Collapsed or unstable |
| P5.1 | Transformer | Curriculum learning | -0.046 | Insufficient |
| P6 | Transformer | NEXT token (remove identity) | -0.082 | Proved data backward bias |
| P6b v2.1 | Transformer | 6-layer defenses + Ï-controller | -0.047 | Improved but still negative |
| P6b v2.2 | Transformer | Stronger pressure (Ï=0.35) | Orthogonal | Escaped constraint |
| P7 | Transformer | InfoNCE ranking + margin | -0.067 | Î»-blend instability |
| **P8** | **Transformer** | **Constrained mixture** | **-0.021** | **Perfect constraint, still backward** |

**Common result**: All approaches failed to achieve positive margin, regardless of architecture or loss design.

---

## Decisive Evidence: Narrative Delta Test

**Question**: Is backward bias specific to Wikipedia/arXiv data, or universal to embedding space?

**Test**: Computed Î” = cos(c_newest, next) - cos(c_newest, prev) on 1,287 paragraph sequences from 5 classic narrative stories.

**Sources**: Frankenstein, Pride and Prejudice, Sherlock Holmes, Alice in Wonderland, Huckleberry Finn (489k characters total).

**Result**:
```json
{
  "mean_delta": 0.0004,          // 100x below 0.10 threshold
  "mean_cos_next": 0.6876,       // Similarity to NEXT paragraph
  "mean_cos_prev": 0.6872,       // Similarity to PREVIOUS paragraph
  "decision": "ABANDON_LVM"
}
```

**Comparison across data sources**:

| Data Source | Scale | Î” (Forward Signal) | Interpretation |
|-------------|-------|-------------------|----------------|
| **Narrative stories** | Paragraphs | **+0.0004** | No forward signal (DECISIVE) |
| arXiv papers | Paragraphs | -0.021 | Weak backward bias |
| Wikipedia | Paragraphs | -0.069 | Strong backward bias |

**Interpretation**: Even classic fiction with clear forward plot structure (setup â†’ payoff) shows **essentially zero forward temporal signal** in GTR-T5 paragraph embeddings.

---

## Root Cause Analysis

### Why GTR-T5 Lacks Forward Temporal Signal

**Training objective**: Masked language modeling (MLM)
- Task: Predict masked tokens from bidirectional context
- Optimization: Maximize similarity between semantically related spans
- **What it learns**: "These chunks discuss similar topics" (symmetric relation)
- **What it does NOT learn**: "This chunk causally follows that chunk" (asymmetric, temporal)

**Evidence from narrative test**:
- A paragraph describing "the butler did it" has **equal similarity** (~0.687) to:
  - Paragraphs BEFORE the reveal (mystery setup, clues)
  - Paragraphs AFTER the reveal (resolution, aftermath)
- Vector geometry is **topic-based** (semantic clustering), not **sequence-based** (temporal ordering)

**This applies at BOTH sentence and paragraph scales**:
- Sentence-level: "The detective found the weapon" equally similar to before/after sentences
- Paragraph-level: "Chapter 5 describes the investigation" equally similar to before/after chapters
- Embedding space encodes **what topics are discussed**, not **when they occur in narrative sequence**

### Why Architecture Cannot Fix This

**P8 proved**: Perfect geometric constraint still fails
- Output constrained to span(context): cos_anchor = 0.974
- No orthogonal escape, no collapse
- **But**: Context vectors themselves have no forward preference
  - If câ‚, câ‚‚, câ‚ƒ, câ‚„, câ‚… all have cos(cáµ¢, prev) â‰ˆ cos(cáµ¢, next)
  - Then ANY mixture q = Î£ Î±áµ¢Â·cáµ¢ also has cos(q, prev) â‰ˆ cos(q, next)

**Analogy**: Trying to build a compass from non-magnetic materials
- Can perfect the compass design (architecture) âœ…
- Can constrain needle to rotate in plane (geometric constraint) âœ…
- **Cannot** make needle point north if materials have no magnetic field âŒ

---

## Decision: Pivot to Retrieval-Only

### What to Keep âœ…

**FAISS retrieval** (production-ready):
- 73.4% Contain@50, 50.2% R@5
- Shard-assist + ANN tuning (nprobe=64)
- MMR diversity reranking (Î»=0.7)
- Directional bonuses for same-article chunks

**DIRECT baseline** (no LVM):
- Just retrieval + reranking
- Already effective for vecRAG applications
- No generative component needed

### What to Archive âŒ

- All AR-LVM models (P1-P8)
- LVM training infrastructure (`app/lvm/train_*.py`)
- Vector-to-vector prediction components

### Optional Future Work ðŸ¤”

**Q-tower ranker** (different task, might work):
- **Task**: Rank candidate chunks by relevance (NOT predict specific next vector)
- **Input**: Query context â†’ query embedding
- **Output**: Relevance scores for retrieved candidates
- **Loss**: Listwise ranking (positive=relevant, negative=irrelevant)
- **Why it might work**: Leverages what embeddings ARE good at (similarity/ranking), not what they're bad at (temporal prediction)
- **Ship gate**: Beat DIRECT by +10pts R@5 and +0.05 MRR@10

---

## Key Lessons

### Technical

1. **Sentence transformers â‰  sequence models**:
   - Trained for: Semantic similarity (retrieval, clustering)
   - NOT trained for: Temporal prediction (generation, autoregression)
   - This limitation applies at both sentence and paragraph scales

2. **Embedding space properties are fundamental**:
   - GTR-T5 geometry: topic-based (symmetric)
   - Needed geometry: sequence-based (asymmetric, temporal)
   - No amount of training tricks can change fundamental geometry

3. **Scale doesn't change the problem**:
   - Sentence level: No forward signal
   - Paragraph level: No forward signal (tested)
   - Chapter level: Likely same issue (not tested, but expected)

### Process

1. **Quick validation tests save time**:
   - P8 pilot: 2 minutes vs. 10 hours (saved 9.5 hours)
   - Narrative test: 8 minutes, decisive result
   - Fast failure >> slow failure

2. **Know when to quit**:
   - After 8 failed approaches, pattern was clear
   - Narrative test provided final proof (Î” = 0.0004, 100x below threshold)
   - Continuing would be sunk cost fallacy

3. **Negative results have value**:
   - Learned: GTR-T5 (and likely all sentence transformers) unsuitable for autoregressive chunk prediction
   - Learned: Retrieval-only already works well (73.4% Contain@50)
   - Can now focus on proven approaches

---

## Files & Documentation

### Created This Session (2025-11-04)

**Scripts**:
- `tools/subset_sequences.py` - Stratified NPZ subset sampling
- `app/lvm/train_p8_pilot.py` - P8 pilot training script
- `tools/narrative_delta_check.py` - Narrative delta validation

**Data**:
- `data/datasets/narrative/*.txt` - 5 classic stories (489k chars)
- `artifacts/lvm/narrative_probe.npz` - 1,287 narrative sequences

**Documentation** (~2,200 lines):
- `artifacts/lvm/P8_PILOT_FAILURE_REPORT.md` - P8 technical analysis
- `artifacts/lvm/NARRATIVE_DELTA_TEST_FINAL.md` - Narrative test results
- `artifacts/lvm/SESSION_FINAL_2025_11_04_COMPLETE.md` - Complete session log
- `artifacts/lvm/EXECUTIVE_SUMMARY_AR_LVM_ABANDONMENT.md` - This document
- Updated `CLAUDE.md` - Final checkpoint

### Existing Documentation

**Training experiments**:
- `artifacts/lvm/P7_BASELINE_FAILURE_REPORT.md` - P7 analysis
- `artifacts/lvm/P6B_V21_IMPLEMENTATION.md` - P6b v2.1 details
- `artifacts/lvm/P6B_EPOCH3_COLLAPSE_ANALYSIS.md` - P6b v1 failure
- `artifacts/lvm/BACKWARD_BIAS_ROOT_CAUSE_REPORT.md` - Wikipedia analysis

**Models** (DO NOT USE):
- `artifacts/lvm/models/transformer_p6b_v21_20251102_182615/` - P6b v2.1
- `artifacts/lvm/models/transformer_p6b_v22_20251102_203637/` - P6b v2.2 (collapsed)
- `artifacts/lvm/models/p7_ranker_c5_m0.07_l0.8_20251104_222516/` - P7
- (P8 pilot not saved - aborted after 2 epochs)

---

## Timeline

- **Oct 2025**: Started LVM experiments (P1-P6)
- **Nov 1**: Wikipedia backward bias analysis (Î” = -0.069)
- **Nov 2**: P6b v2.1, v2.2 (both failed)
- **Nov 4 (early)**: P7 trained and failed
- **Nov 4 (evening)**: P8 pilot failed, narrative test DECISIVE
- **Nov 4 (late)**: Decision to abandon AR-LVM

**Total duration**: ~2 months
**Total experiments**: 8 failed training attempts + 1 decisive validation test
**Final decision**: Abandon autoregressive LVM, pivot to retrieval-only vecRAG

---

## Bottom Line

**After rigorous testing** (8 architectures, 3 data sources, paragraph-level embeddings):

**Finding**: GTR-T5 paragraph embeddings do not encode forward temporal signal. This is a fundamental property of how sentence transformers are trained (MLM with bidirectional context), not a data-specific artifact.

**Decision**: Stop autoregressive vector-to-vector chunk prediction. Focus on retrieval-only vecRAG (already works well).

**Next session**: Archive LVM code, update documentation, focus on proven retrieval approaches.

---

*Report date: 2025-11-04*
*Author: Claude (with human oversight)*
*Status: FINAL - AR-LVM project closed*
