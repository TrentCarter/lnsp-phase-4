[Architect]
What’s wrong (from the sample)
CPESH is effectively missing
1/3 has a placeholder, 2/3 have no CPESH. This means your CPESH builder isn’t firing, or your join key between doc/chunk and CPESH is wrong.
Symptom: your “permanent lake” exists only as text + TMD; your retrieval and training signals (Concept/Probe/Expected, negatives) aren’t there.
TMD looks collapsed to a default
All three are 9.1.27 (History.FactRetrieval.Descriptive). Either the extractor is defaulting to a single class or you’re not passing the fields used for routing.
Expectation: at least Domain variance across entries (e.g., Literature vs History). Uniform TMD = broken mapping or fallback path.
Chunks are too skinny for CPESH generation
Word counts: 41 / 90 / 58. CPESH needs enough context to extract a concept, a probe, and a grounded expected answer (plus negs). Sub-100 words is brittle.
Likely your chunker is slicing on tiny spans (title/section one-liners) or using a summary field, not the source body.
Title / section edge-cases aren’t normalized
Titles like ! (Cláudia Pascoal album) and section “Plot summary” show you’ll hit punctuation/markup quirks. If those leak into concept_text or the join key, CPESH generation/join will silently skip.
“Complete” criteria is too strict or improperly wired
You have “3 COMPLETE DATABASE ENTRIES,” which implies the completeness gate is mis-specified (e.g., requires TMD but not CPESH, or vice versa). Given CPESH is absent, the gate isn’t catching what matters.
Fast triage plan (do these in this order)
A. Verify joins & keys (30 min)
Ensure each text chunk has a stable join into CPESH rows:
doc_id (e.g., enwiki-00000108), section_id (or start/end), chunk_id, and lane_index.
Build/repair a mapping table in cpesh_index.db:
map(doc_id, chunk_start, chunk_end) → list<cpe_id>, plus lane_index and created_at.
Quick check: count chunks with ≥1 CPESH; target >90% after backfill.
B. Regenerate CPESH for thin chunks (2 passes)
Pass 1 (cheap): batch the current tiny chunks into context windows (e.g., merge contiguous chunks until 180–320 words), re-run CPESH builder.
Pass 2 (correct): fix chunker:
Semantic splitter (embedding similarity or sentence-level cohesion),
Constraints: 120–300 words, keep sections intact, collapse single-sentence titles with following body.
C. Fix TMD assignment (stop the defaulting)
Confirm extractor receives features it needs (title, section, content, metadata).
Dump a TMD histogram; if one bin dominates, you’re defaulting.
Add a rule: reject TMD=default unless confidence ≥τ; otherwise fall back to Unknown lane and flag for reprocess.
D. Harden CPESH builder I/O
Normalize titles (strip leading punctuation, normalize Unicode).
Require outputs: concept_text, probe_question, expected_answer; if any is blank, mark validation_status=failed with a reason.
Negatives: start with soft negatives only; generate hard later from confusable concepts (cosine ≥0.7 in same lane).
E. Update “complete entry” gate
Redefine COMPLETE = has {text ≥120w, TMD != default, CPESH passed, fused_vec present}.
Your report should show BOTH: total entries and complete entries %, plus reasons for incompleteness.
Concrete “one-hour” fixes (ready-to-implement)
Validator (CI):
Fail if mean(words_per_chunk) < 120 or P95 < 250.
Fail if TMD_default_rate > 0.2.
Warn if cpesh_attach_rate < 0.9.
Rechunker defaults:
Target 180–320 words; join adjacent sentences until min≥140 words; never split inside a section header boundary.
CPESH backfill job:
Read incomplete rows → batch by doc_id → grouped context → CPESH builder → write cpesh_active.jsonl → rotate to Parquet + update cpesh_index.db.
TMD sanity check:
If (Domain=History) but content_type=Literature/Plot, bump to Literature lane and log a remap.
ASCII status (make lnsp-status):
───────────────────────────────────────────────
LNSPRAG STATUS
───────────────────────────────────────────────
Total chunks:         12,340
Complete entries:     8,976 (72.7%)
 - Too short:         1,944
 - TMD default:         789
 - CPESH missing:     1,087
Mean chunk words:       186
CPESH attach rate:     91.2%
TMD default rate:        6.4%
───────────────────────────────────────────────
Design choices I’d lock now (to unblock GWOM + LVM)
Lean vectors as default: fused_vec(784D) + question_vec(768D); keep full only for research shards.
Minimum viable CPESH: require only (C, P, E) for pass; negatives are optional until Phase 2.
Lane-first gating: if TMD default, do not use CPESH for nprobe downshift; force nprobe=16.
Chunk policy: 180–320 word targets; section-aware; Unicode-normalized.
Quick tests you (or I) can run on today’s dump
Distribution check:
% chunks with words < 100
% chunks with TMD default
% chunks with 0 CPESH
Avg CPESH per chunk (should trend to 1–3)
Spot CPESH quality:
For 20 random CPESH items, is expected_answer verbatim supported by the chunk? (binary). Target ≥0.8.
GWOM readiness:
Can we form a GraphRAG walk of length ≥7 within a single lane from current CPESH? If not, chunking or TMD is still off.
Likely root causes behind your exact 3 rows
ID/key mismatch between enwiki-… and CPESH cpe_id mapping → no joins → “has entry but no data.”
Default TMD due to extractor fallback (missing features or confidence threshold too high).
Over-eager splitting produced “title-only” or “plot-stub” shards that are too short for CPESH.
What I can produce next (without waiting)
A validator script spec (CLI + exit codes) that prints the ASCII dashboard and fails CI on the thresholds above.
A cpesh_backfill.py spec that batches short chunks into windows and re-runs the builder.
A TMD histogram + confusion report that flags domains likely misrouted (History vs Literature, etc.).