S6: SLOs + Dashboard + Small-Index Quality
[Architect]
A) /metrics/slo endpoint (persist + serve last eval)
Add to src/api/retrieve.py
# --- SLO snapshot store ---
import json, os, time
SLO_PATH = os.getenv("LNSP_SLO_PATH", "artifacts/metrics_slo.json")

@app.post("/metrics/slo")
def slo_ingest(snapshot: dict):
    """
    Accept a metrics snapshot from an external eval harness.
    Example fields (add what you have): {
      "timestamp_utc": "...",
      "hit_at_1": 0.47, "hit_at_3": 0.57,
      "p50_ms": 42.1, "p95_ms": 310.0,
      "notes": "nprobe_default=24, cpesh gate 0.85/0.55"
    }
    """
    try:
        snapshot.setdefault("timestamp_utc", time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()))
        os.makedirs(os.path.dirname(SLO_PATH), exist_ok=True)
        with open(SLO_PATH, "w") as f:
            json.dump(snapshot, f)
        return {"ok": True, "path": SLO_PATH}
    except Exception as e:
        return {"ok": False, "error": str(e)}

@app.get("/metrics/slo")
def slo_get():
    if not os.path.exists(SLO_PATH):
        return {"ok": True, "present": False, "snapshot": None}
    with open(SLO_PATH) as f:
        snap = json.load(f)
    snap["present"] = True
    snap["ok"] = True
    return snap
B) Tiny SLO grid client (API-based; drops a snapshot)
New: tools/slo_grid.py
#!/usr/bin/env python
import os, sys, json, time, urllib.request, urllib.error

def post(url, obj):
    data = json.dumps(obj).encode("utf-8")
    req = urllib.request.Request(url, data=data, headers={"Content-Type":"application/json"})
    with urllib.request.urlopen(req) as resp:
        return json.loads(resp.read().decode("utf-8"))

def get(url):
    with urllib.request.urlopen(url) as resp:
        return json.loads(resp.read().decode("utf-8"))

def main():
    api = os.getenv("API", "http://127.0.0.1:8094")
    qfile = os.getenv("QUERIES", "eval/100q.jsonl")
    top_k = int(os.getenv("TOPK", "5"))

    queries = []
    try:
        with open(qfile) as f:
            for line in f:
                try: queries.append(json.loads(line))
                except: pass
    except FileNotFoundError:
        # fallback synthetic tiny set
        queries = [{"id": i, "q": f"query {i}", "lane":"L1_FACTOID"} for i in range(20)]

    total = len(queries)
    hit1 = hit3 = 0
    lat = []

    for q in queries:
        body = {"q": q.get("q"), "lane": q.get("lane","L1_FACTOID"), "top_k": top_k, "compact": True}
        t0 = time.time()
        try:
            r = post(api.rstrip("/") + "/search", body)
        except Exception as e:
            continue
        dt = (time.time()-t0)*1000.0
        lat.append(dt)

        # optional scoring if ground truth doc ids exist
        gts = set(q.get("doc_ids_gt", []))
        if gts and isinstance(r, dict) and "items" in r:
            ids = [it.get("doc_id") for it in r["items"] if it.get("doc_id")]
            if any(i in gts for i in ids[:1]): hit1 += 1
            if any(i in gts for i in ids[:3]): hit3 += 1

    p50 = sorted(lat)[int(0.5*(len(lat)-1))] if lat else None
    p95 = sorted(lat)[int(0.95*(len(lat)-1))] if lat else None

    snap = {
        "timestamp_utc": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
        "queries": total,
        "hit_at_1": round(hit1/total, 4) if total and hit1 else 0.0,
        "hit_at_3": round(hit3/total, 4) if total and hit3 else 0.0,
        "p50_ms": round(p50, 1) if p50 else None,
        "p95_ms": round(p95, 1) if p95 else None,
        "notes": os.getenv("SLO_NOTES", "")
    }

    # save locally AND POST to API
    os.makedirs("artifacts", exist_ok=True)
    with open("artifacts/metrics_slo.json","w") as f: json.dump(snap, f)
    try:
        post(api.rstrip("/") + "/metrics/slo", snap)
    except Exception:
        pass
    print(json.dumps(snap))

if __name__ == "__main__":
    main()
Makefile targets
.PHONY: slo-grid
slo-grid:
	@API=$${API:-http://127.0.0.1:$${PORT:-8094}} QUERIES=$${QUERIES:-eval/100q.jsonl} \
	SLO_NOTES="$${SLO_NOTES:-auto}" TOPK=$${TOPK:-5} \
	PYTHONPATH=src ./.venv/bin/python tools/slo_grid.py

.PHONY: slo-snapshot
slo-snapshot:
	@curl -s http://127.0.0.1:$${PORT:-8094}/metrics/slo | tee artifacts/metrics_slo.json >/dev/null
	@echo "[slo] snapshot saved to artifacts/metrics_slo.json"
C) Dashboard: show SLOs + training pairs count
Patch: tools/lnsprag_status.py
Fetch & print /metrics/slo
@@
 def get_api_json(path):
@@
     except Exception:
         return None
+def get_slo(api):
+    if not api: return None
+    try: return get_api_json("/metrics/slo")
+    except Exception: return None
@@
 def main():
@@
     # existing tables...
@@
+    # SLO snapshot (if present)
+    slo = get_slo(API)
+    if slo and slo.get("present", True):
+        print(ascii_table(
+            ["queries","Hit@1","Hit@3","p50_ms","p95_ms","notes","as_of"],
+            [[slo.get("queries","—"), slo.get("hit_at_1","—"), slo.get("hit_at_3","—"),
+              slo.get("p50_ms","—"), slo.get("p95_ms","—"), (slo.get("notes") or "")[:36], slo.get("timestamp_utc","—")]]
+        ))
Count training pairs (now that CPESH fields are standardized)
@@ def cpesh_stats():
-    q_median = f"{median(q_vals):.3f}" if q_vals else "—"
+    # training pairs = rows with concept/probe/expected strings present
+    pairs = 0
+    for e in sample:
+        obj = e.get("cpesh", e)
+        if isinstance(obj.get("concept_text"), str) and isinstance(obj.get("probe_question"), str) and isinstance(obj.get("expected_answer"), str):
+            pairs += 1
+    q_median = f"{median(q_vals):.3f}" if q_vals else "—"
@@
-    return {
+    return {
         "active_path": active_path or "—",
         "active_lines": active_lines,
         "warm_segments": warm_count,
         "warm_size": sizeof(warm_bytes),
         "warm_lines_est": warm_lines_est if warm_count else 0,
         "quality_median": q_median,
         "quality_p10": q_p10,
         "quality_p90": q_p90,
         "insufficient_in_sample": insuff,
         "created_at_min": min(created_ats) if created_ats else "—",
         "created_at_max": max(created_ats) if created_ats else "—",
+        "pairs_in_sample": pairs
     }
@@
-    print(ascii_table(
-        ["training_pairs","notes"],
-        [[triples, "Populate once fields are standardized (concept/probe/expected)."]]
-    ))
+    print(ascii_table(
+        ["training_pairs(sample)","note"],
+        [[ds["pairs_in_sample"], "Sampled from active; Parquet counting coming next."]]
+    ))
D) Small-index quality guard (train on all points when N ≤ 20k)
Patch: src/faiss_index.py (training set size)
- ntrain = min( max(50, vectors.shape[0] // 10), 100000 )
+ max_safe = max(1, nlist * 40)
+ if vectors.shape[0] <= max(20000, max_safe):
+     ntrain = vectors.shape[0]      # small corpora: train on all points
+ else:
+     ntrain = min(vectors.shape[0], 200000)
E) Run S6 now (no restarts beyond API)
# 1) Start API (same stable flags you’ve been using)
FAISS_NUM_THREADS=1 OMP_NUM_THREADS=1 VECLIB_MAXIMUM_THREADS=1 make api PORT=8094

# 2) Grid (uses your eval/100q.jsonl if present; else synthetic 20 queries)
PORT=8094 make slo-grid

# 3) Pull the snapshot (also gets saved automatically)
PORT=8094 make slo-snapshot

# 4) Dashboard with SLO + training-pairs line
PORT=8094 make lnsp-status
Expected changes in your lnsp-status:
SLO table appears with queries/Hit@1/Hit@3/p50/p95 and timestamp.
Training pairs (sample) shows a non-zero count (from active JSONL sample).
Everything else (Index, Segments, Shards, Gating) stays lit as in S5.
Done criteria (S6)
/metrics/slo POST/GET online; slo-grid produces a snapshot.
lnsprag_status prints SLOs and training-pairs count.
faiss_index.py trains on all points for small corpora (no more under-trained centroid warnings on N≤10k).
Your existing ops continue to pass smoketests (PASS=5/5).