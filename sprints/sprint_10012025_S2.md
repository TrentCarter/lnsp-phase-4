  Sprint 2: OCP Training Data Preparation

  Tasks:
  1. Extract training sequences from ontology chains:
  # Convert 173K chains → training sequences
  ./.venv/bin/python -m src.lvm.prepare_ocp_sequences \
      --ontology-chains artifacts/ontology_chains/*.jsonl \
      --output artifacts/lvm/ocp_training.npz \
      --min-chain-length 3 \
      --max-chain-length 15
  2. Generate vectors for all sequences:
    - Use GTR-T5 embeddings (already computed for 9.5K)
    - Batch encode remaining concepts from 173K chains
    - Store in NPZ: [N_sequences, max_length, 768]
  3. Create train/val/test splits:
    - 70% train / 15% val / 15% test
    - Stratify by ontology source (SWO, GO, DBpedia) and chain length

  Exit criteria:
  - artifacts/lvm/ocp_training.npz contains ~800K training examples
  - All vectors pre-computed (no runtime embedding overhead)
  - Splits balanced across ontology sources

[Director] Comments:
Why not starty with our current 10k ingested concepts? 
I thought the vector database was populated when the vecRAG was populated as part of the injestion phase? (This is concerning; I was expecing CPESH + TMD 768+16 to already be in a vector database)
  Exit criteria: COMMENTS
  - artifacts/lvm/ocp_training.npz contains ~800K training examples >>. Shouldnt that be 10k?
  - All vectors pre-computed (no runtime embedding overhead) >>. Agree
  - Splits balanced across ontology sources >>. Agree

Update 1:
  Sprint 2: Prepare OCP Training Data (FROM CURRENT 9.5K)

  Task 1: Extract training sequences from INGESTED concepts
  # File: src/lvm/extract_ocp_sequences.py

  def extract_sequences_from_current_data():
      """
      Extract training sequences from 9,477 already-ingested concepts.
      No need to wait for 173K - use what we have NOW.
      """

      # Query Postgres for all ingested concepts with their relationships
      conn = psycopg2.connect("dbname=lnsp")
      cur = conn.cursor()

      cur.execute("""
          SELECT 
              e.cpe_id,
              e.concept_text,
              e.relations_text,
              e.tmd_lane,
              v.concept_vec,
              v.tmd_dense
          FROM cpe_entry e
          JOIN cpe_vectors v USING (cpe_id)
          WHERE e.validation_status = 'passed'
          ORDER BY e.created_at;
      """)

      concepts = cur.fetchall()

      # Build sequences from relationships in Neo4j
      sequences = []
      for concept in concepts:
          # Get ordered chain from Neo4j (if part of ontology)
          chain = neo4j_get_chain(concept['cpe_id'])

          if len(chain) >= 3:
              # Create training pairs: predict next from context
              vectors = [c['concept_vec'] for c in chain]
              for i in range(2, len(vectors)):
                  sequences.append({
                      'context': vectors[:i],
                      'target': vectors[i],
                      'tmd': chain[0]['tmd_dense'],
                  })

      return sequences  # Expected: ~45K sequences from 9.5K concepts

  Task 2: Export to NPZ format
  # Create training NPZ from current database
  ./.venv/bin/python -m src.lvm.extract_ocp_sequences \
      --output artifacts/lvm/ocp_training_9k.npz \
      --min-chain-length 3 \
      --max-chain-length 15

  Task 3: Train/Val/Test split
  # Split: 70/15/15
  # Expected sizes:
  # - Train: ~31.5K sequences
  # - Val: ~6.75K sequences
  # - Test: ~6.75K sequences

  Exit Criteria (CORRECTED):
  - ✅ artifacts/lvm/ocp_training_9k.npz contains ~45K training examples (not 800K)
  - ✅ All vectors pre-computed (loaded from cpe_vectors table)
  - ✅ Splits balanced across ontology sources (SWO, GO, DBpedia)

  ## Vector Dimensions (CLARIFICATION):
  - **Training inputs**: 768D concept vectors from GTR-T5 (from `cpe_vectors.concept_vec`)
  - **Optional conditioning**: 16D TMD encoding (from `cpe_vectors.tmd_dense`)
  - **Total per token**: 768D or 784D (768+16) depending on TMD usage
  - **Note**: Faiss/vecRAG uses 784D fused vectors for retrieval; LVM training can use either 768D or 784D

---

## TASK ASSIGNMENTS

### Task 2.1: [Architect] Design OCP Sequence Extraction Algorithm
**Owner:** [Architect]
**Priority:** Critical Path
**Estimated Time:** 3-4 hours

**Objective:**
Design and implement algorithm to extract ~45K training sequences from 9,477 ingested ontology concepts using Postgres + Neo4j chain traversal.

**Technical Specification:**
```python
# File: src/lvm/extract_ocp_sequences.py

import psycopg2
import numpy as np
from neo4j import GraphDatabase

def extract_sequences_from_current_data(
    min_chain_length=3,
    max_chain_length=15,
    output_path="artifacts/lvm/ocp_training_9k.npz"
):
    """
    Extract autoregressive training sequences from ingested ontology chains.

    Data Flow:
    1. Query Postgres for all valid CPE entries with vectors
    2. For each concept, query Neo4j for its ontology chain
    3. Build context→target pairs: predict vec[i] from vec[0:i]
    4. Filter by chain length (3-15 concepts)
    5. Export to NPZ with train/val/test splits

    Expected Output:
    - ~45K training sequences from 9.5K concepts
    - Each sequence: (context_vecs, target_vec, tmd_dense, metadata)
    - 70/15/15 train/val/test split, stratified by source
    """

    # Step 1: Load all concepts with vectors from Postgres
    conn = psycopg2.connect("dbname=lnsp user=postgres")
    cur = conn.cursor()

    query = """
        SELECT
            e.cpe_id,
            e.concept_text,
            e.source_type,
            e.tmd_lane,
            e.tmd_bits,
            v.concept_vec,
            v.tmd_dense,
            v.fused_vec
        FROM cpe_entry e
        JOIN cpe_vectors v USING (cpe_id)
        WHERE e.validation_status = 'passed'
          AND v.concept_vec IS NOT NULL
        ORDER BY e.source_type, e.created_at;
    """

    cur.execute(query)
    concepts = {
        row[0]: {
            'cpe_id': row[0],
            'text': row[1],
            'source': row[2],
            'tmd_lane': row[3],
            'tmd_bits': row[4],
            'concept_vec': np.array(row[5]),
            'tmd_dense': np.array(row[6]),
            'fused_vec': np.array(row[7])
        }
        for row in cur.fetchall()
    }

    print(f"Loaded {len(concepts)} concepts from Postgres")

    # Step 2: Query Neo4j for ontology chains
    neo4j_driver = GraphDatabase.driver(
        "bolt://localhost:7687",
        auth=("neo4j", "password")
    )

    sequences = []

    with neo4j_driver.session() as session:
        # Find all ontology chains (paths with IS_A, PART_OF relations)
        result = session.run("""
            MATCH path = (start:Concept)-[:IS_A|PART_OF*1..15]->(end:Concept)
            WHERE start.source IN ['swo', 'go', 'dbpedia']
            RETURN [node in nodes(path) | node.cpe_id] as chain_ids,
                   length(path) as chain_len
        """)

        for record in result:
            chain_ids = record['chain_ids']
            chain_len = record['chain_len']

            # Filter by length
            if chain_len < min_chain_length or chain_len > max_chain_length:
                continue

            # Get vectors for all concepts in chain
            chain_vecs = []
            valid_chain = True
            for cpe_id in chain_ids:
                if cpe_id not in concepts:
                    valid_chain = False
                    break
                chain_vecs.append(concepts[cpe_id])

            if not valid_chain:
                continue

            # Create training pairs: predict vec[i] from vec[0:i]
            for i in range(2, len(chain_vecs)):
                context = [c['concept_vec'] for c in chain_vecs[:i]]
                target = chain_vecs[i]['concept_vec']
                tmd = chain_vecs[0]['tmd_dense']  # Use root TMD
                source = chain_vecs[0]['source']

                sequences.append({
                    'context': np.array(context),  # [i, 768]
                    'target': target,              # [768]
                    'tmd': tmd,                    # [16]
                    'source': source,              # 'swo', 'go', or 'dbpedia'
                    'chain_length': len(chain_vecs),
                    'context_length': i,
                })

    print(f"Extracted {len(sequences)} training sequences")

    # Step 3: Train/val/test split (70/15/15) stratified by source
    from sklearn.model_selection import train_test_split

    sources = [s['source'] for s in sequences]

    train_idx, temp_idx = train_test_split(
        range(len(sequences)),
        test_size=0.3,
        stratify=sources,
        random_state=42
    )

    val_idx, test_idx = train_test_split(
        temp_idx,
        test_size=0.5,
        stratify=[sources[i] for i in temp_idx],
        random_state=42
    )

    # Step 4: Export to NPZ
    np.savez_compressed(
        output_path,
        train_context=[sequences[i]['context'] for i in train_idx],
        train_target=[sequences[i]['target'] for i in train_idx],
        train_tmd=[sequences[i]['tmd'] for i in train_idx],
        val_context=[sequences[i]['context'] for i in val_idx],
        val_target=[sequences[i]['target'] for i in val_idx],
        val_tmd=[sequences[i]['tmd'] for i in val_idx],
        test_context=[sequences[i]['context'] for i in test_idx],
        test_target=[sequences[i]['target'] for i in test_idx],
        test_tmd=[sequences[i]['tmd'] for i in test_idx],
        metadata={
            'total_sequences': len(sequences),
            'train_size': len(train_idx),
            'val_size': len(val_idx),
            'test_size': len(test_idx),
            'source_counts': {
                'swo': sum(1 for s in sequences if s['source'] == 'swo'),
                'go': sum(1 for s in sequences if s['source'] == 'go'),
                'dbpedia': sum(1 for s in sequences if s['source'] == 'dbpedia'),
            }
        }
    )

    print(f"Saved to {output_path}")
    print(f"  Train: {len(train_idx)} sequences")
    print(f"  Val: {len(val_idx)} sequences")
    print(f"  Test: {len(test_idx)} sequences")

    return sequences, train_idx, val_idx, test_idx
```

**Implementation Steps:**
1. Connect to Postgres and load all 9,477 concepts with vectors
2. Connect to Neo4j and query all ontology chains (IS_A, PART_OF paths)
3. For each chain of length 3-15, create context→target training pairs
4. Apply 70/15/15 train/val/test split stratified by source
5. Export to NPZ with all splits and metadata

**Deliverables:**
- `src/lvm/extract_ocp_sequences.py` implementation
- `artifacts/lvm/ocp_training_9k.npz` with ~45K sequences
- Documentation: Algorithm explanation, data format specification
- Validation script: `tests/test_ocp_sequences.py`

**Exit Criteria:**
- ✅ ~45K sequences extracted (±10% acceptable)
- ✅ All sequences have valid context, target, and TMD vectors
- ✅ Train/val/test split is 70/15/15 (±2%)
- ✅ Source distribution balanced across splits

---

### Task 2.2: [Programmer] Implement Sequence Builder and NPZ Export
**Owner:** [Programmer]
**Priority:** Critical Path
**Estimated Time:** 2-3 hours

**Objective:**
Implement robust sequence builder with error handling, validation, and efficient NPZ export for training pipeline.

**Technical Specification:**
```python
# File: src/lvm/sequence_builder.py

import numpy as np
from dataclasses import dataclass
from typing import List, Dict, Tuple

@dataclass
class TrainingSequence:
    """
    Single training example for autoregressive LVM training.

    Attributes:
    - context: List of 768D vectors (length 2-14)
    - target: 768D vector to predict
    - tmd: 16D TMD metadata vector
    - metadata: Dict with source, chain_length, etc.
    """
    context: np.ndarray  # [context_len, 768]
    target: np.ndarray   # [768]
    tmd: np.ndarray      # [16]
    metadata: Dict

    def validate(self) -> bool:
        """
        Validate sequence has correct shapes and no NaN/Inf values.
        """
        # Check shapes
        if self.context.ndim != 2 or self.context.shape[1] != 768:
            return False
        if self.target.shape != (768,):
            return False
        if self.tmd.shape != (16,):
            return False

        # Check for NaN/Inf
        if np.any(np.isnan(self.context)) or np.any(np.isinf(self.context)):
            return False
        if np.any(np.isnan(self.target)) or np.any(np.isinf(self.target)):
            return False
        if np.any(np.isnan(self.tmd)) or np.any(np.isinf(self.tmd)):
            return False

        # Check context length
        if len(self.context) < 2 or len(self.context) > 14:
            return False

        return True


class SequenceDataset:
    """
    Container for training sequences with efficient batching and export.
    """

    def __init__(self, sequences: List[TrainingSequence]):
        self.sequences = [s for s in sequences if s.validate()]
        print(f"Validated {len(self.sequences)}/{len(sequences)} sequences")

    def export_to_npz(
        self,
        output_path: str,
        train_idx: List[int],
        val_idx: List[int],
        test_idx: List[int]
    ):
        """
        Export sequences to NPZ with train/val/test splits.

        NPZ Format:
        - Ragged arrays: Use object dtype to store variable-length contexts
        - train_context: Array of [context_len, 768] arrays
        - train_target: Array of [768] vectors
        - train_tmd: Array of [16] vectors
        """

        def extract_split(indices):
            return (
                np.array([self.sequences[i].context for i in indices], dtype=object),
                np.array([self.sequences[i].target for i in indices]),
                np.array([self.sequences[i].tmd for i in indices])
            )

        train_ctx, train_tgt, train_tmd = extract_split(train_idx)
        val_ctx, val_tgt, val_tmd = extract_split(val_idx)
        test_ctx, test_tgt, test_tmd = extract_split(test_idx)

        # Compute statistics
        context_lengths = [len(self.sequences[i].context) for i in train_idx]
        sources = [self.sequences[i].metadata['source'] for i in train_idx]

        np.savez_compressed(
            output_path,
            train_context=train_ctx,
            train_target=train_tgt,
            train_tmd=train_tmd,
            val_context=val_ctx,
            val_target=val_tgt,
            val_tmd=val_tmd,
            test_context=test_ctx,
            test_target=test_tgt,
            test_tmd=test_tmd,
            metadata=np.array([{
                'total_sequences': len(self.sequences),
                'train_size': len(train_idx),
                'val_size': len(val_idx),
                'test_size': len(test_idx),
                'mean_context_length': np.mean(context_lengths),
                'max_context_length': np.max(context_lengths),
                'source_distribution': {
                    src: sum(1 for s in sources if s == src)
                    for src in set(sources)
                }
            }], dtype=object)[0]
        )

        print(f"Exported to {output_path}")
        print(f"  Train: {len(train_idx)} sequences")
        print(f"  Val: {len(val_idx)} sequences")
        print(f"  Test: {len(test_idx)} sequences")
        print(f"  Mean context length: {np.mean(context_lengths):.2f}")
```

**Implementation Steps:**
1. Create `TrainingSequence` dataclass with validation
2. Implement `SequenceDataset` container with NPZ export
3. Handle ragged arrays (variable-length contexts) using object dtype
4. Add comprehensive error handling and validation
5. Test with small sample before full export

**Deliverables:**
- `src/lvm/sequence_builder.py` implementation
- Unit tests: `tests/test_sequence_builder.py`
- Example usage script: `examples/build_sequences.py`
- Documentation: Data format and validation rules

**Exit Criteria:**
- ✅ All sequences pass validation (no NaN/Inf, correct shapes)
- ✅ NPZ export handles variable-length contexts correctly
- ✅ Unit tests pass with 100% coverage
- ✅ NPZ file loads successfully in PyTorch DataLoader

---

### Task 2.3: [Consultant] Create Train/Val/Test Split Strategy
**Owner:** [Consultant]
**Priority:** High
**Estimated Time:** 2 hours

**Objective:**
Design and validate stratified split strategy to ensure balanced representation across ontology sources and chain lengths.

**Split Requirements:**
```python
# File: src/lvm/split_strategy.py

from sklearn.model_selection import StratifiedKFold, train_test_split
import numpy as np

def stratified_split_by_source(
    sequences: List[TrainingSequence],
    train_ratio=0.7,
    val_ratio=0.15,
    test_ratio=0.15,
    random_seed=42
) -> Tuple[List[int], List[int], List[int]]:
    """
    Create stratified train/val/test splits ensuring balanced source distribution.

    Stratification Variables:
    - Primary: Source type (swo, go, dbpedia)
    - Secondary: Chain length bucket (3-5, 6-10, 11-15)

    Validation Checks:
    - Source distribution within ±3% across splits
    - Chain length distribution within ±5% across splits
    - No data leakage: Ensure same ontology chain doesn't appear in multiple splits
    """

    # Create stratification labels: "{source}_{length_bucket}"
    strat_labels = []
    for seq in sequences:
        source = seq.metadata['source']
        chain_len = seq.metadata['chain_length']

        if chain_len <= 5:
            bucket = 'short'
        elif chain_len <= 10:
            bucket = 'medium'
        else:
            bucket = 'long'

        strat_labels.append(f"{source}_{bucket}")

    # First split: train vs (val+test)
    train_idx, temp_idx = train_test_split(
        range(len(sequences)),
        test_size=(val_ratio + test_ratio),
        stratify=strat_labels,
        random_state=random_seed
    )

    # Second split: val vs test
    temp_labels = [strat_labels[i] for i in temp_idx]
    val_idx, test_idx = train_test_split(
        temp_idx,
        test_size=test_ratio / (val_ratio + test_ratio),
        stratify=temp_labels,
        random_state=random_seed
    )

    # Validate splits
    validate_splits(sequences, train_idx, val_idx, test_idx)

    return train_idx, val_idx, test_idx


def validate_splits(
    sequences: List[TrainingSequence],
    train_idx: List[int],
    val_idx: List[int],
    test_idx: List[int]
):
    """
    Validate that splits are balanced and have no data leakage.
    """

    def get_distribution(indices, key):
        values = [sequences[i].metadata[key] for i in indices]
        counts = {v: values.count(v) for v in set(values)}
        total = len(values)
        return {k: v/total for k, v in counts.items()}

    # Check source distribution
    train_sources = get_distribution(train_idx, 'source')
    val_sources = get_distribution(val_idx, 'source')
    test_sources = get_distribution(test_idx, 'source')

    print("Source Distribution:")
    print(f"  Train: {train_sources}")
    print(f"  Val:   {val_sources}")
    print(f"  Test:  {test_sources}")

    # Check that distributions are within ±3%
    for source in train_sources.keys():
        train_pct = train_sources.get(source, 0)
        val_pct = val_sources.get(source, 0)
        test_pct = test_sources.get(source, 0)

        assert abs(train_pct - val_pct) < 0.03, f"{source} imbalance: train={train_pct:.3f}, val={val_pct:.3f}"
        assert abs(train_pct - test_pct) < 0.03, f"{source} imbalance: train={train_pct:.3f}, test={test_pct:.3f}"

    print("✅ Source distribution balanced within ±3%")

    # Check for data leakage (same chain in multiple splits)
    train_chains = set(sequences[i].metadata.get('chain_id') for i in train_idx)
    val_chains = set(sequences[i].metadata.get('chain_id') for i in val_idx)
    test_chains = set(sequences[i].metadata.get('chain_id') for i in test_idx)

    overlap = (train_chains & val_chains) | (train_chains & test_chains) | (val_chains & test_chains)
    assert len(overlap) == 0, f"Data leakage: {len(overlap)} chains in multiple splits"

    print("✅ No data leakage detected")
```

**Validation Metrics:**
- Source distribution: swo/go/dbpedia within ±3% across splits
- Chain length distribution: short/medium/long within ±5% across splits
- Size ratios: 70/15/15 (±2% acceptable)
- No data leakage: Zero chains appearing in multiple splits

**Deliverables:**
- `src/lvm/split_strategy.py` implementation
- Validation report: Distribution tables and leakage check
- Unit tests: `tests/test_split_strategy.py`
- Documentation: Stratification methodology

**Exit Criteria:**
- ✅ 70/15/15 split ratios achieved (±2%)
- ✅ Source distribution balanced within ±3%
- ✅ Chain length distribution balanced within ±5%
- ✅ Zero data leakage detected

---

### Task 2.4: [Architect] Pre-computed Vector Validation
**Owner:** [Architect]
**Priority:** Sprint Exit Gate
**Estimated Time:** 1-2 hours

**Objective:**
Verify all 9,477 vectors are accessible, normalized, and ready for training with no runtime embedding overhead.

**Validation Script:**
```python
# File: tests/validate_vectors_ready.py

import psycopg2
import numpy as np

def validate_all_vectors():
    """
    Comprehensive validation of pre-computed vectors in database.

    Checks:
    1. All 9,477 CPE entries have corresponding vectors
    2. All vectors have correct dimensions (768D concept, 16D TMD, 784D fused)
    3. All vectors are normalized (L2 norm ≈ 1.0)
    4. No NaN or Inf values
    5. Vectors are accessible in <1ms per query
    """

    conn = psycopg2.connect("dbname=lnsp")
    cur = conn.cursor()

    # Check 1: Count completeness
    cur.execute("SELECT COUNT(*) FROM cpe_entry;")
    entry_count = cur.fetchone()[0]

    cur.execute("SELECT COUNT(*) FROM cpe_vectors;")
    vector_count = cur.fetchone()[0]

    assert entry_count == vector_count, f"Mismatch: {entry_count} entries, {vector_count} vectors"
    print(f"✅ Vector completeness: {vector_count}/{entry_count} (100%)")

    # Check 2: Dimension validation
    cur.execute("""
        SELECT
            array_length(concept_vec::float[], 1) as concept_dim,
            array_length(tmd_dense::float[], 1) as tmd_dim,
            array_length(fused_vec::float[], 1) as fused_dim
        FROM cpe_vectors
        LIMIT 1;
    """)
    concept_dim, tmd_dim, fused_dim = cur.fetchone()

    assert concept_dim == 768, f"Concept vec should be 768D, got {concept_dim}D"
    assert tmd_dim == 16, f"TMD vec should be 16D, got {tmd_dim}D"
    assert fused_dim == 784, f"Fused vec should be 784D, got {fused_dim}D"
    print(f"✅ Vector dimensions: concept={concept_dim}D, tmd={tmd_dim}D, fused={fused_dim}D")

    # Check 3: Normalization
    cur.execute("SELECT concept_vec FROM cpe_vectors LIMIT 100;")
    vectors = [np.array(row[0]) for row in cur.fetchall()]
    norms = [np.linalg.norm(v) for v in vectors]

    mean_norm = np.mean(norms)
    assert 0.95 < mean_norm < 1.05, f"Vectors not normalized: mean norm = {mean_norm:.4f}"
    print(f"✅ Vector normalization: mean L2 norm = {mean_norm:.4f}")

    # Check 4: No NaN/Inf
    cur.execute("""
        SELECT COUNT(*) FROM cpe_vectors
        WHERE 'NaN' = ANY(concept_vec::text::float[])
           OR 'Infinity' = ANY(concept_vec::text::float[]);
    """)
    nan_count = cur.fetchone()[0]
    assert nan_count == 0, f"Found {nan_count} vectors with NaN/Inf values"
    print(f"✅ No NaN/Inf values detected")

    # Check 5: Query performance
    import time
    cur.execute("SELECT concept_vec FROM cpe_vectors ORDER BY RANDOM() LIMIT 1000;")

    start = time.time()
    vectors = cur.fetchall()
    elapsed = time.time() - start

    ms_per_query = (elapsed / 1000) * 1000
    assert ms_per_query < 1.0, f"Slow vector access: {ms_per_query:.2f}ms per query"
    print(f"✅ Vector access performance: {ms_per_query:.3f}ms per query")

    print("\n🎉 All vectors validated and ready for training!")
    return True


if __name__ == "__main__":
    validate_all_vectors()
```

**Deliverables:**
- `tests/validate_vectors_ready.py` validation script
- Validation report: Pass/fail for all checks
- Performance benchmarks: Vector access latency
- Sprint 2 completion checklist

**Exit Criteria:**
- ✅ All 9,477 vectors accessible in database
- ✅ All vectors have correct dimensions and normalization
- ✅ No NaN/Inf values detected
- ✅ Vector access latency <1ms per query
- ✅ Ready for Sprint 3 training pipeline