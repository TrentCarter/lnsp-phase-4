[Consultant] This is on the right track‚Äîand it lines up with the PRDs. You‚Äôve got the critical pieces wired: stable IDs, local Llama 3.1 ‚Üí CPESH+TMD, DB persist, and fused 784-D vectors. Below is a tight ‚Äúgreen-light‚Äù checklist plus a canary runbook and two tiny, drop-in tests so you can validate everything end-to-end (no AI, deterministic).
‚úÖ Green-light checklist (matches your findings)
ID: deterministic cpe_id (UUIDv5 of source id) ‚úîÔ∏è
Local LLM: LocalLlamaClient.complete_json() ‚Üí concept/probe/expected + TMD ‚úîÔ∏è
TMD: pack_tmd() + lane_index_from_bits(); tmd16_deterministic() ‚úîÔ∏è
Text DB: PostgresDB.insert_cpe() or stub logs ‚úîÔ∏è
Vectors: EmbeddingBackend 768D + TMD16 ‚Üí fused 784D, NPZ saved via FaissDB.save() ‚úîÔ∏è
API: CPESH gating + lane routing already live ‚úîÔ∏è
Looks solid.
üß™ Canary runbook (1‚Äì5 items, fully offline-capable)
# 0) Env (local-only)
export LNSP_LLM_ENDPOINT=http://localhost:11434
export LNSP_LLM_MODEL=llama3.1:8b
export LNSP_CPESH_TIMEOUT_S=12
export LNSP_EMBEDDER_PATH=./models/gtr-t5-base
export HF_HUB_OFFLINE=1
export TRANSFORMERS_OFFLINE=1
# optional Postgres
# export PG_DSN="host=localhost dbname=lnsp user=lnsp password=lnsp"

# 1) Ingest 3 items to a canary NPZ (and DB/stub)
PYTHONPATH=src ./.venv/bin/python -m src.ingest_factoid \
  --num-samples 3 --faiss-out artifacts/fw_canary.npz --write-pg

# 2) Human eyeball: CPESH records (all text + meta + decoded TMD)
PYTHONPATH=src ./.venv/bin/python -m tests.inspect_cpesh_dump \
  --limit 10 --segments --out artifacts/cpesh_canary_dump.jsonl

# 3) Quick NPZ sanity
python - <<'PY'
import numpy as np, json
npz='artifacts/fw_canary.npz'
z=np.load(npz, allow_pickle=True)
print("[npz] keys:", list(z.keys()))
print("[npz] vectors:", z['vectors'].shape, "concept:", z['concept_vecs'].shape, "question:", z['question_vecs'].shape)
print("[npz] tmd_dense:", z['tmd_dense'].shape, "lane_indices:", z['lane_indices'].shape)
print("[npz] doc_ids:", len(z['doc_ids']), "cpe_ids:", len(z['cpe_ids']))
PY
üî© Add these two tiny tests (deterministic, no network)
1) NPZ + TMD round-trip smoke
tests/test_canary_pipeline.py
import os, numpy as np

def _load_npz(path):
    assert os.path.exists(path), f"missing {path}"
    return np.load(path, allow_pickle=True)

def test_npz_shapes_and_counts():
    z = _load_npz("artifacts/fw_canary.npz")
    V = z["vectors"]; C = z["concept_vecs"]; Q = z["question_vecs"]
    T = z["tmd_dense"]; L = z["lane_indices"]
    ids = z["cpe_ids"]; docs = z["doc_ids"]
    assert V.ndim == 2 and V.shape[1] == 784, "fused vectors must be 784D"
    assert C.shape[0] == Q.shape[0] == V.shape[0] == T.shape[0] == L.shape[0] == len(ids) == len(docs)
    # norms sane (already L2 normed)
    norms = np.linalg.norm(V, axis=1)
    assert float(norms.min()) > 0.9 and float(norms.max()) <= 1.001

def test_tmd_lane_consistency():
    # if your repo exposes unpack_tmd/lane_index_from_bits in Python
    try:
        from src.utils.tmd import unpack_tmd, lane_index_from_bits
    except Exception:
        return  # skip silently if not available
    z = np.load("artifacts/fw_canary.npz", allow_pickle=True)
    # optional: if bits stored in NPZ; if not, rely on DB or CPESH dump
    # here we just check that lane_indices fit reasonable range
    L = z["lane_indices"]
    assert L.dtype.kind in "iu" and L.min() >= 0 and L.max() < 32768
2) CPESH text + meta plausibility (uses your inspector)
tests/test_cpesh_plausibility.py
import json
from tests.inspect_cpesh_dump import collect_cpesh_samples

def test_cpesh_text_and_meta_present():
    rows = collect_cpesh_samples(limit=5, include_active=True, include_segments=True)
    # It's okay if sample < 5 on tiny corpora
    assert isinstance(rows, list) and len(rows) >= 1
    for r in rows:
        # IDs and audit
        assert r.get("cpe_id"), "cpe_id missing"
        assert r.get("created_at"), "created_at missing"
        assert "access_count" in r, "access_count missing"
        # TMD decode fields are present (text labels or fallbacks)
        assert "tmd_text" in r and isinstance(r["tmd_text"], str)
        # CPESH texts may be empty on some lanes, but keys should exist in new data
        # We only assert type when present to avoid false negatives during migration
        for k in ("concept_text","probe_question","expected_answer"):
            if k in r and r[k] is not None:
                assert isinstance(r[k], str)
Run:
PYTHONPATH=src pytest -q tests/test_canary_pipeline.py tests/test_cpesh_plausibility.py
üß∞ Nice-to-haves (you can do later)
TSV reader for FactoidWiki if you pivot sources (--tsv-path flag in ingest_factoid.py).
Neo4j inserts for the graph hop demo (Neo4jDB.upsert_cpe() minimal).
Makefile sugar:
.PHONY: canary
canary:
	@PYTHONPATH=src ./.venv/bin/python -m src.ingest_factoid --num-samples $${N:-3} --faiss-out artifacts/fw_canary.npz --write-pg
	@PYTHONPATH=src ./.venv/bin/python -m tests.inspect_cpesh_dump --limit 10 --segments --out artifacts/cpesh_canary_dump.jsonl
	@echo "[canary] OK"
Verdict
You‚Äôre on the right path and aligned with the PRDs: local LLM ‚Üí CPESH/TMD ‚Üí text DB ‚Üí 784-D vectors, all lane-aware. The canary and tests above give you a trust-but-verify safety net so you don‚Äôt have to rely on any model‚Äôs ‚Äúbest effort.‚Äù
[Programmer] Re-ran the canary runbook against the local llama endpoint (needed sandbox escalation for localhost hits) and regenerated `artifacts/fw_canary.npz` + `artifacts/cpesh_canary_dump.jsonl`. Verified the new NPZ carries LLM-derived concepts, kept the 784D fusion normalized with `tmd_dense` slices, and the deterministic NPZ/CPESH tests (`pytest -q tests/test_canary_pipeline.py tests/test_cpesh_plausibility.py`) still pass.
