{
  "project": {
    "metadata": {
      "id": "VMMoE_Production_V1p3_FastConverge",
      "name": "VMMoE Production Training v1.3 - Fast Convergence",
      "description": "Optimized for rapid convergence based on v1.1 success pattern - minimal changes for maximum impact",
      "version": "1.3.0",
      "created_date": "2025-08-14",
      "training_date": "2025-08-14T16:xx",
      "notes": "Keep architecture from v1.1, optimize hyperparameters for 3-epoch convergence"
    },
    "model": "sentence-transformers/gtr-t5-base",
    "local_model_path": "data/teacher_models/gtr-t5-base"
  },
  "training": {
    "architecture": {
      "mamba_config": {
        "d_model": 768,
        "n_layers": 4,
        "d_state": 16,
        "d_conv": 4,
        "expand": 1.5,
        "dt_rank": "auto",
        "dt_min": 0.001,
        "dt_max": 0.1,
        "dt_init": "random",
        "dt_scale": 1.0,
        "bias": false,
        "conv_bias": true
      },
      "positional_config": {
        "mode": "learned",
        "max_len": 512
      }
    },
    "loss_config": {
      "loss_type": "triplet",
      "margin_start": 0.1,
      "margin_end": 0.25,
      "margin_schedule": "cosine",
      "cosine_weight": 0.7,
      "mse_weight": 0.15,
      "contrastive_weight": 0.15,
      "orthogonality_weight": 0.002
    },
    "optimization": {
      "optimizer": "AdamW",
      "learning_rate": 8e-05,
      "weight_decay": 0.02,
      "gradient_clipping": 0.5,
      "warmup_steps": 200,
      "scheduler": "cosine_with_restarts",
      "t_mult": 2,
      "eta_min": 1e-06
    },
    "data": {
      "batch_size": 20,
      "sequence_length": 16,
      "num_workers": 0,
      "shuffle": true,
      "drop_last": true,
      "concept_databases": [
        "data/databases/concept_vector_db_768_training"
      ]
    },
    "training_params": {
      "epochs": 8,
      "steps_per_epoch": 300,
      "validation_frequency": 5,
      "checkpoint_frequency": 50,
      "device_priority": [
        "mps",
        "cuda",
        "cpu"
      ]
    },
    "early_stopping": {
      "enabled": true,
      "patience": 4,
      "min_delta": 0.00001,
      "monitor": "val/loss",
      "mode": "min",
      "min_epochs": 3,
      "loss_target": 0.005,
      "loss_target_enabled": true,
      "verbose": true
    }
  },
  "evaluation": {
    "validation_split": 0.08,
    "metrics": [
      "retrieval_at_1",
      "mean_cosine_similarity",
      "triplet_accuracy"
    ]
  },
  "mlflow": {
    "tracking_uri": "http://localhost:5006",
    "experiment_name": "vmmoe_stable_v1p3",
    "run_name_prefix": "production_v1p3_fast",
    "log_models": true,
    "log_metrics_frequency": 1
  },
  "checkpointing": {
    "checkpoint_dir": "output/vmmoe_stable_v1p3",
    "save_best": true,
    "embed_config": true
  },
  "improvements": {
    "from_v1.1": {
      "learning_rate": "5e-05 → 8e-05 (1.6x for faster initial convergence)",
      "margin_end": "0.2 → 0.25 (better separation)",
      "margin_schedule": "linear → cosine (smoother)",
      "batch_size": "16 → 20 (25% increase, still MPS-friendly)",
      "warmup": "2500 → 200 steps (faster ramp-up)",
      "epochs": "50 → 8 (focused training)",
      "steps_per_epoch": "500 → 300 (2400 total steps)",
      "scheduler": "cosine → cosine_with_restarts",
      "loss_weights": "adjusted for better balance"
    },
    "from_v1.2_fixes": {
      "architecture": "Kept simple 4-layer (v1.2's 6 layers too slow)",
      "batch_size": "32 → 20 (v1.2 too large for MPS)",
      "learning_rate": "2e-04 → 8e-05 (v1.2 too aggressive)",
      "removed": "Complex augmentation, hard negative mining",
      "focus": "Simple, fast convergence like v1.1"
    },
    "expected_results": {
      "convergence": "3 epochs to reach loss < 0.01",
      "training_time": "~30 minutes total",
      "final_loss": "< 0.005",
      "stability": "Smooth convergence without d_ap upturn"
    }
  }
}