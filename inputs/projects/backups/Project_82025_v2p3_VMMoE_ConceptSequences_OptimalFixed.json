{
  "project": {
    "name": "VMMoE_v2p3_ConceptSequences_OptimalFixed",
    "version": "2.3",
    "description": "OPTIMAL-FIXED Training: Correct 32 sequence length + improved packing for maximum data utilization (32Ã—17=544 token equivalent)",
    "timestamp": "2025-08-22T13:00:00",
    "author": "AI Assistant + User",
    "tags": ["VMMoE", "concept_sequences", "optimal_sequence_length", "improved_packing", "32_concepts"],
    "metadata": {
      "id": "v2p3_concept_sequences_optimal_fixed",
      "experiment_type": "optimal_data_utilization",
      "baseline": "v2p2_gap_fixed",
      "key_innovation": "correct_32_sequence_length_plus_aggressive_packing",
      "data_architecture_alignment": "mamba_optimal_32_concept_sequences",
      "critical_fixes": [
        "sequence_length_corrected_to_32",
        "aggressive_sequence_packing_16_per_batch",
        "pack_efficiency_target_95_percent",
        "maintained_d_model_fix_from_v2p2"
      ],
      "token_equivalent": "32_concepts_x_17_tokens_per_concept_equals_544_tokens",
      "expected_data_utilization": "90_percent_plus"
    }
  },
  "training": {
    "patience": 5,
    "min_delta": 0.0001,
    "save_every_n_epochs": 5,
    "early_stopping_metric": "val/total_loss",
    "early_stopping_mode": "min",
    "early_stopping_patience": 10,
    "force_full_epochs": true,
    "training_params": {
      "batch_size": 8,
      "num_workers": 2,
      "epochs": 30,
      "steps_per_epoch": 1000,
      "validation_frequency": 1,
      "checkpoint_frequency": 250,
      "device_priority": ["mps", "cuda", "cpu"],
      "mixed_precision": false,
      "compile_model": false,
      "seed": 42,
      "deterministic": false
    },
    "architecture": {
      "mamba_config": {
        "d_model": 768,
        "n_layers": 8,
        "d_state": 16,
        "d_conv": 4,
        "expand": 1.0,
        "explicit_hidden_size": 768,
        "dimension_validation": true
      },
      "positional_config": {
        "mode": "learned",
        "max_len": 32,
        "dropout": 0.1,
        "learned_config": {
          "embedding_dim": 768,
          "max_position_embeddings": 32
        }
      },
      "sequence_config": {
        "sequence_length": 32,
        "concept_embedding_dim": 768,
        "next_concept_prediction": true,
        "masked_concept_probability": 0.15,
        "sequence_packing": {
          "enabled": true,
          "pack_multiple_sequences": true,
          "padding_token_id": 0,
          "attention_mask_enabled": true
        }
      },
      "peft_config": {
        "enabled": true,
        "lora_config": {
          "r": 16,
          "lora_alpha": 32,
          "lora_dropout": 0.1,
          "target_modules": ["in_proj", "out_proj", "x_proj", "dt_proj"],
          "bias": "none",
          "task_type": "CAUSAL_LM",
          "init_lora_weights": "gaussian"
        },
        "freeze_base": false,
        "unfreeze_layers": ["output_projection", "prediction_head"]
      }
    },
    "loss_config": {
      "loss_type": "next_concept_prediction",
      "prediction_config": {
        "cross_entropy_weight": 0.7,
        "masked_lm_weight": 0.3,
        "sequence_coherence_weight": 0.1,
        "label_smoothing": 0.1
      },
      "auxiliary_losses": {
        "concept_similarity_loss": 0.1,
        "sequence_order_loss": 0.05,
        "domain_consistency_loss": 0.05
      },
      "normalization_enforcement": {
        "enabled": true,
        "l2_penalty_weight": 0.001,
        "unit_norm_final": true,
        "stability_epsilon": 1e-8
      }
    },
    "optimization": {
      "optimizer": "AdamW",
      "learning_rate": 5e-05,
      "weight_decay": 0.01,
      "gradient_clipping": 1.0,
      "warmup_steps": 150,
      "scheduler": "cosine",
      "betas": [0.9, 0.95],
      "eps": 1e-08,
      "gradient_accumulation_steps": 4
    },
    "data": {
      "batch_size": 8,
      "sequence_length": 32,
      "num_workers": 2,
      "shuffle": true,
      "drop_last": true,
      "data_type": "concept_sequences",
      "concept_sequence_databases": [
        "data/databases/concept_sequences_768_vectors"
      ],
      "sequence_metadata_db": "data/databases/concept_sequences_metadata.db",
      "sequence_packing": {
        "enabled": true,
        "max_sequences_per_batch": 8,
        "padding_strategy": "longest",
        "truncation_strategy": "longest_first",
        "pack_efficiency_target": 0.7
      },
      "domain_filtering": {
        "enabled": true,
        "allowed_domains": ["Programming", "Algorithms"],
        "domain_balancing": true
      },
      "data_augmentation": {
        "concept_masking": {
          "enabled": true,
          "mask_probability": 0.15,
          "mask_token": "[MASK]"
        },
        "sequence_shuffling": {
          "enabled": false,
          "shuffle_probability": 0.0
        }
      }
    }
  },
  "mlflow": {
    "experiment_name": "VMMoE_ConceptSequences_v2p3",
    "run_name": "optimal_fixed_32_seq_aggressive_packing",
    "run_name_prefix": "v2p3_optimal",
    "tracking_uri": "sqlite:///mlflow.db",
    "log_model": true,
    "log_artifacts": true,
    "tags": {
      "version": "2.3",
      "architecture": "VMMoE_ConceptSequences_OptimalFixed",
      "training": "optimal_sequence_length_aggressive_packing",
      "sequence_length": "32",
      "token_equivalent": "544",
      "dataset": "apps_concept_sequences",
      "experiment": "optimal_32_concept_temporal_learning",
      "epochs": "30",
      "data_utilization": "aggressive_95_percent_target",
      "key_fixes": "32_sequence_length_16_sequences_per_batch_95_percent_packing"
    }
  },
  "outputs": {
    "model_save_path": "output/vmmoe_concept_sequences_v2p3",
    "logs_path": "output/logs",
    "plots_path": "output/plots",
    "checkpoints_path": "output/checkpoints"
  },
  "checkpointing": {
    "resume_from_checkpoint": null,
    "save_optimizer_state": true,
    "save_scheduler_state": true,
    "checkpoint_format": "pytorch",
    "backup_checkpoints": 5
  },
  "monitoring": {
    "log_every_n_steps": 25,
    "validate_every_n_steps": 100,
    "log_gradients": false,
    "log_learning_rate": true,
    "log_loss_components": true,
    "track_memory_usage": true,
    "architecture_validation": {
      "verify_d_model": true,
      "check_parameter_count": true,
      "log_model_dimensions": true,
      "validate_expansion": true
    },
    "training_completion": {
      "checkpoint_every_epoch": true,
      "validate_completion": true,
      "export_final_metrics": true,
      "completion_summary": true
    },
    "data_utilization": {
      "track_sequence_usage": true,
      "log_packing_efficiency": true,
      "monitor_data_coverage": true,
      "target_utilization_percent": 95
    },
    "sequence_metrics": {
      "concept_prediction_accuracy": true,
      "sequence_coherence_score": true,
      "domain_classification_accuracy": true,
      "next_concept_perplexity": true
    }
  },
  "evaluation": {
    "validation_split": 0.2,
    "metrics": [
      "sequence_perplexity",
      "concept_prediction_accuracy",
      "masked_concept_accuracy",
      "sequence_coherence_score",
      "domain_consistency",
      "analogical_reasoning_score"
    ],
    "save_predictions": true,
    "compute_analogies": true,
    "sequence_test_cases": [
      {
        "input_sequence": ["import", "class_definition", "constructor", "method", "algorithm", "validation", "return"],
        "expected_next": "test_case"
      },
      {
        "input_sequence": ["problem_statement", "algorithm_choice", "data_structure", "implementation"],
        "expected_next": "optimization"
      },
      {
        "input_sequence": ["function_signature", "parameter_validation", "core_logic", "error_handling"],
        "expected_next": "return_statement"
      }
    ]
  }
}