{
  "project": {
    "metadata": {
      "id": "VMMoE_Production_V1p9_Refined",
      "name": "VMMoE Production Training v1.9 - Refined Early Stopping",
      "description": "V1.9 refined to stop at optimal Epoch 2 based on V1.8 analysis",
      "version": "1.9.0",
      "created_date": "2025-08-15",
      "training_date": "2025-08-15T17:xx",
      "notes": "Ultra-sensitive early stopping at Epoch 2, slower margin, gentler learning"
    },
    "model": "sentence-transformers/gtr-t5-base",
    "local_model_path": "data/teacher_models/gtr-t5-base"
  },
  "training": {
    "architecture": {
      "mamba_config": {
        "d_model": 768,
        "n_layers": 5,
        "d_state": 24,
        "d_conv": 6,
        "expand": 1.75,
        "dt_rank": "auto",
        "dt_min": 0.001,
        "dt_max": 0.1,
        "dt_init": "xavier",
        "dt_scale": 0.9,
        "bias": false,
        "conv_bias": true,
        "dropout": 0.15,
        "layer_norm_epsilon": 1e-5
      },
      "positional_config": {
        "mode": "hybrid",
        "learned_weight": 0.7,
        "sinusoidal_weight": 0.3,
        "max_len": 512,
        "dropout": 0.1,
        "learned_config": {
          "embedding_dim": 768,
          "max_position_embeddings": 512
        },
        "sinusoidal_config": {
          "embedding_dim": 768,
          "temperature": 10000.0
        }
      },
      "peft_config": {
        "enabled": true,
        "adapter_type": "lora",
        "lora_rank": 12,
        "lora_alpha": 24,
        "lora_dropout": 0.05,
        "target_modules": [
          "in_proj",
          "x_proj",
          "dt_proj",
          "A_log",
          "D",
          "out_proj"
        ],
        "modules_to_save": [
          "layer_norm"
        ]
      }
    },
    "loss_config": {
      "loss_type": "triplet",
      "margin_start": 0.05,
      "margin_end": 0.15,
      "margin_schedule": "linear",
      "cosine_weight": 0.65,
      "mse_weight": 0.125,
      "contrastive_weight": 0.2,
      "orthogonality_weight": 0.0015,
      "temperature": 0.05,
      "label_smoothing": 0.05,
      "normalization_enforcement": {
        "enabled": true,
        "l2_penalty_weight": 0.0005,
        "cosine_similarity_threshold": 0.03,
        "normalize_embeddings": true,
        "stability_epsilon": 1e-8
      }
    },
    "optimization": {
      "optimizer": "AdamW",
      "learning_rate": 5e-05,
      "weight_decay": 0.02,
      "gradient_clipping": 1.0,
      "warmup_steps": 500,
      "scheduler": "cosine_with_restarts",
      "restart_interval": 2325,
      "restart_multiplier": 1.0,
      "betas": [0.9, 0.98],
      "eps": 1e-08
    },
    "data": {
      "batch_size": 24,
      "sequence_length": 16,
      "num_workers": 2,
      "shuffle": true,
      "drop_last": true,
      "concept_databases": [
        "data/databases/concept_vector_db_768_training",
        "data/databases/qa_training_triplets_768d"
      ],
      "augmentation": {
        "enabled": true,
        "noise_std": 0.008,
        "dropout_prob": 0.05,
        "mixup_alpha": 0.2
      }
    },
    "training_params": {
      "epochs": 3,
      "steps_per_epoch": 2325,
      "validation_frequency": 1,
      "checkpoint_frequency": 775,
      "device_priority": [
        "mps",
        "cuda",
        "cpu"
      ],
      "seed": 42,
      "deterministic": false
    },
    "early_stopping": {
      "enabled": true,
      "patience": 0,
      "min_delta": 0.001,
      "monitor": "val/anchor_positive_distance",
      "mode": "min",
      "min_epochs": 2,
      "loss_target": 0.32,
      "loss_target_enabled": true,
      "verbose": true,
      "restore_best_weights": true,
      "additional_criteria": {
        "max_d_ap": 0.105,
        "min_d_an": 0.14,
        "max_overfit_ratio": 2.0,
        "min_ap_cos": 0.03,
        "max_epochs": 3
      }
    },
    "regularization": {
      "dropout": 0.12,
      "attention_dropout": 0.05,
      "weight_noise": 0.001,
      "gradient_noise": 0.0001,
      "ema_decay": 0.999,
      "stochastic_depth": 0.08
    }
  },
  "evaluation": {
    "validation_split": 0.07,
    "metrics": [
      "retrieval_at_1",
      "retrieval_at_5",
      "mean_cosine_similarity",
      "triplet_accuracy",
      "semantic_coherence"
    ],
    "semantic_tests": {
      "enabled": true,
      "test_analogies": true,
      "test_clustering": true
    }
  },
  "mlflow": {
    "tracking_uri": "http://localhost:5006",
    "experiment_name": "vmmoe_stable_v1p9",
    "run_name_prefix": "refined_v1p9",
    "log_models": true,
    "log_metrics_frequency": 1,
    "log_artifacts": true,
    "log_visualizations": true
  },
  "checkpointing": {
    "checkpoint_dir": "output/vmmoe_stable_v1p9",
    "save_best": true,
    "save_last": true,
    "save_on_early_stop": true,
    "embed_config": true,
    "save_optimizer_state": false,
    "save_every_n_epochs": 1
  },
  "strategy": {
    "philosophy": "V1.9 Refined - Stop at optimal Epoch 2 based on V1.8 analysis",
    "key_insights": {
      "optimal_point": "Epoch 2 (steps ~4650) showed best d_ap=0.10",
      "early_stopping": "Ultra-sensitive with patience=0 to catch optimal point",
      "margin_schedule": "Slower progression to 0.15 max instead of 0.25",
      "learning_rate": "Gentler 5e-05 with longer warmup",
      "lora_rank": "Slightly higher (12) for more expressiveness"
    },
    "improvements_from_v1_8": {
      "early_stopping": {
        "patience": "1 → 0 (stop immediately on degradation)",
        "monitor": "val/loss → val/anchor_positive_distance (direct metric)",
        "max_epochs": "10 → 3 (hard limit based on analysis)",
        "min_epochs": "2 (ensure we reach the sweet spot)"
      },
      "learning": {
        "learning_rate": "7e-05 → 5e-05 (gentler)",
        "warmup_steps": "200 → 500 (smoother start)",
        "restart_interval": "500 → 2325 (one per epoch)"
      },
      "margin": {
        "margin_start": "0.06 → 0.05 (lower start)",
        "margin_end": "0.25 → 0.15 (prevent over-separation)",
        "schedule": "cosine → linear (simpler progression)"
      },
      "normalization": {
        "l2_penalty": "0.001 → 0.0005 (lighter touch)",
        "cosine_threshold": "0.05 → 0.03 (tighter control)"
      },
      "lora": {
        "rank": "8 → 12 (more capacity)",
        "dropout": "0.1 → 0.05 (less regularization)"
      }
    },
    "expected_results": {
      "convergence": "Exactly 2-3 epochs (stop at optimal)",
      "final_loss": "~0.30-0.32 (Epoch 2 target)",
      "d_ap": "~0.10 (best from V1.8)",
      "d_an": "~0.15 (maintained separation)",
      "training_time": "~30-45 minutes (3 epochs max)",
      "quality": "Capture V1.8 Epoch 2 performance consistently"
    },
    "monitoring": {
      "critical_metrics": [
        "val/anchor_positive_distance (must stay < 0.105)",
        "val/anchor_negative_distance (must stay > 0.14)",
        "Training stops immediately if d_ap degrades",
        "Checkpoint every 775 steps (3 per epoch)"
      ],
      "watch_for": [
        "Stop at first sign of d_ap increase",
        "Ensure 2 full epochs complete",
        "Hard stop at 3 epochs maximum",
        "Save checkpoint at optimal point"
      ]
    }
  }
}