{
  "project": {
    "metadata": {
      "id": "VMMoE_Production_V1p5_Optimal",
      "name": "VMMoE Production Training v1.5 - Optimal Balance",
      "description": "Carefully tuned based on v1.1-v1.4 learnings: moderate LR, aggressive early stopping, regularization",
      "version": "1.5.0",
      "created_date": "2025-08-15",
      "training_date": "2025-08-15T00:xx",
      "notes": "Sweet spot configuration: Stop at loss 0.005-0.008 for best semantic quality"
    },
    "model": "sentence-transformers/gtr-t5-base",
    "local_model_path": "data/teacher_models/gtr-t5-base"
  },
  "training": {
    "architecture": {
      "mamba_config": {
        "d_model": 768,
        "n_layers": 4,
        "d_state": 20,
        "d_conv": 5,
        "expand": 1.5,
        "dt_rank": "auto",
        "dt_min": 0.001,
        "dt_max": 0.1,
        "dt_init": "xavier",
        "dt_scale": 0.9,
        "bias": false,
        "conv_bias": true,
        "dropout": 0.1,
        "layer_norm_epsilon": 1e-5
      },
      "positional_config": {
        "mode": "learned",
        "max_len": 512,
        "dropout": 0.1
      }
    },
    "loss_config": {
      "loss_type": "triplet",
      "margin_start": 0.08,
      "margin_end": 0.22,
      "margin_schedule": "cosine",
      "cosine_weight": 0.75,
      "mse_weight": 0.125,
      "contrastive_weight": 0.125,
      "orthogonality_weight": 0.0015,
      "temperature": 0.07,
      "label_smoothing": 0.05
    },
    "optimization": {
      "optimizer": "AdamW",
      "learning_rate": 6e-05,
      "weight_decay": 0.015,
      "gradient_clipping": 0.7,
      "warmup_steps": 300,
      "scheduler": "cosine",
      "betas": [0.9, 0.98],
      "eps": 1e-08
    },
    "data": {
      "batch_size": 18,
      "sequence_length": 16,
      "num_workers": 2,
      "shuffle": true,
      "drop_last": true,
      "concept_databases": [
        "data/databases/concept_vector_db_768_training"
      ],
      "augmentation": {
        "enabled": true,
        "noise_std": 0.005,
        "dropout_prob": 0.05
      }
    },
    "training_params": {
      "epochs": 10,
      "steps_per_epoch": 400,
      "validation_frequency": 1,
      "checkpoint_frequency": 50,
      "device_priority": [
        "mps",
        "cuda",
        "cpu"
      ],
      "seed": 42,
      "deterministic": false
    },
    "early_stopping": {
      "enabled": true,
      "patience": 2,
      "min_delta": 0.0005,
      "monitor": "val/loss",
      "mode": "min",
      "min_epochs": 2,
      "loss_target": 0.008,
      "loss_target_enabled": true,
      "verbose": true,
      "restore_best_weights": true,
      "additional_criteria": {
        "max_d_ap": 0.05,
        "min_d_an": 0.15,
        "max_overfit_ratio": 3.0
      }
    },
    "regularization": {
      "dropout": 0.1,
      "attention_dropout": 0.05,
      "weight_noise": 0.001,
      "gradient_noise": 0.0001,
      "ema_decay": 0.999,
      "stochastic_depth": 0.05
    }
  },
  "evaluation": {
    "validation_split": 0.07,
    "metrics": [
      "retrieval_at_1",
      "retrieval_at_5",
      "mean_cosine_similarity",
      "triplet_accuracy",
      "semantic_coherence"
    ],
    "semantic_tests": {
      "enabled": true,
      "test_analogies": true,
      "test_clustering": true
    }
  },
  "mlflow": {
    "tracking_uri": "http://localhost:5006",
    "experiment_name": "vmmoe_stable_v1p5",
    "run_name_prefix": "optimal_v1p5",
    "log_models": true,
    "log_metrics_frequency": 1,
    "log_artifacts": true,
    "log_visualizations": true
  },
  "checkpointing": {
    "checkpoint_dir": "output/vmmoe_stable_v1p5",
    "save_best": true,
    "save_last": true,
    "save_on_early_stop": true,
    "embed_config": true,
    "save_optimizer_state": false
  },
  "strategy": {
    "philosophy": "Quality over quantity - preserve semantic understanding",
    "key_insights": {
      "loss_sweet_spot": "0.005-0.008 (not near zero!)",
      "training_duration": "2-4 epochs typically sufficient",
      "learning_rate": "6e-05 (between v1.1's 5e-05 and v1.3's 8e-05)",
      "batch_size": "18 (optimal for MPS memory bandwidth)",
      "regularization": "Multiple techniques to prevent overfitting",
      "early_stopping": "Aggressive - stop as soon as quality peaks"
    },
    "improvements_from_v1_4": {
      "architecture": {
        "d_state": "16 → 20 (slightly more capacity)",
        "d_conv": "4 → 5 (better temporal modeling)",
        "dropout": "Added 0.1 dropout throughout",
        "initialization": "xavier for better gradient flow"
      },
      "loss": {
        "margin_range": "0.08-0.22 (tighter than before)",
        "temperature": "Added for better contrastive learning",
        "label_smoothing": "0.05 to prevent overconfidence"
      },
      "training": {
        "batch_size": "16 → 18 (slight increase)",
        "steps_per_epoch": "500 → 400 (fewer but quality steps)",
        "validation_freq": "5 → 3 (more frequent checks)",
        "warmup": "500 → 300 (faster ramp-up)"
      },
      "early_stopping": {
        "patience": "3 → 2 (more aggressive)",
        "loss_target": "0.01 → 0.008 (stop earlier)",
        "additional_criteria": "Added d_ap/d_an thresholds",
        "overfit_ratio": "Stop if val_loss > 3x train_loss"
      },
      "regularization": {
        "weight_decay": "0.01 → 0.015",
        "dropout": "Added throughout architecture",
        "noise": "Weight and gradient noise added",
        "ema": "Exponential moving average for stability",
        "stochastic_depth": "Random layer dropping"
      }
    },
    "expected_results": {
      "convergence": "2-3 epochs to optimal",
      "final_loss": "0.005-0.008 (intentionally not lower)",
      "d_ap": "< 0.05 (tight positive clustering)",
      "d_an": "> 0.15 (good negative separation)",
      "semantic_quality": "Preserved - no nonsense outputs",
      "training_time": "~20-30 minutes",
      "generalization": "Better than all previous versions"
    },
    "monitoring": {
      "watch_for": [
        "Loss dropping below 0.005 (stop immediately)",
        "d_ap rising above 0.05 (losing clustering)",
        "d_an falling below 0.15 (poor separation)",
        "Val/train ratio > 3 (overfitting)"
      ],
      "visualizations": [
        "Domain clustering plot",
        "Inter-domain heatmap",
        "Training progress infographic"
      ]
    }
  }
}