# Two-Tower V4 Training Status Report
**Date:** October 22, 2025
**Author:** Claude (Autonomous Training System)
**Status:** üö® **ALL TRAINING RUNS CRASHED**

---

## Executive Summary

**CRITICAL:** All 4 training attempts (2 MPS, 2 CPU) failed to complete. Only 1 pre-validation checkpoint saved successfully.

### Key Findings
- ‚ùå **0 completed training runs** (0 best.pt files created)
- ‚ö†Ô∏è **1 pre-validation checkpoint** saved (CPU test, epoch 1)
- üî¥ **Training instability** observed on both MPS and CPU
- üìã **New PRD created**: Dual-Path vecRAG + LVM system

---

## Training Attempts Summary

### Run 1: MPS Simple (07:31:01)
- **Device:** MPS (Apple Silicon GPU)
- **Config:** Batch 16√ó2=32, 15 epochs, 25k bank
- **Status:** ‚ùå Crashed mid-training
- **Last step:** Unknown (log truncated)
- **Checkpoint:** None

### Run 2: MPS Balanced (07:17:17)
- **Device:** MPS
- **Config:** Batch 16√ó3=48, 20 epochs, 35k bank
- **Status:** ‚ùå Crashed mid-training
- **Last step:** Unknown (log truncated)
- **Checkpoint:** None

### Run 3: MPS Final (07:43:39)
- **Device:** MPS
- **Config:** Batch 16√ó4=64, 30 epochs, 50k bank, full async mining
- **Status:** ‚ùå Crashed around step ~770/2243
- **Symptoms:**
  - Queue warnings: "Output queue empty - consider increasing prefetch"
  - Training slowdowns (10.67 it/s ‚Üí 8.31 it/s)
  - Sudden log termination
- **Checkpoint:** None
- **Estimated progress:** ~34% of epoch 1

### Run 4: CPU Test (08:05:32)
- **Device:** CPU
- **Config:** Batch 8√ó2=16, 3 epochs, 10k bank, NO async mining
- **Status:** ‚ùå Crashed after step ~1000/4487
- **Checkpoint:** ‚úÖ **epoch_001_pre_validation.pt** (54 MB)
- **Estimated progress:** ~22% of epoch 1

---

## Checkpoint Analysis

### `runs/twotower_v4_cpu_test/checkpoints/epoch_001_pre_validation.pt`

**Size:** 54 MB
**Created:** October 22, 2025 08:10 AM

**Contents:**
```python
{
  'epoch': 1,
  'model_q_state_dict': {...},  # Query tower weights
  'model_d_state_dict': {...},  # Doc tower weights (identity, minimal)
  'optimizer_state_dict': {...}, # Adam optimizer state
  'config': {...}                # Training configuration
}
```

**Value:**
- ‚úÖ Saved BEFORE validation crashed (as designed)
- ‚úÖ Contains both model towers + optimizer state
- ‚úÖ Can be used to resume training or inspect learned weights
- ‚ö†Ô∏è Only ~22% through epoch 1 - very early training stage

**Why This Checkpoint Matters:**
Per our Oct 22 fixes (tools/train_twotower_v4.py:823-832), we added pre-validation checkpointing to capture model state BEFORE validation runs. This worked perfectly - the checkpoint was saved before the crash occurred.

---

## Root Cause Analysis

### Observed Failure Patterns

1. **MPS Runs: All crashed during async mining**
   - Symptom: "Output queue empty" warnings
   - Symptom: Training slowdowns followed by sudden termination
   - Hypothesis: Async FAISS mining + MPS interaction causing race conditions

2. **CPU Run: Crashed during training loop**
   - No async mining (disabled for CPU test)
   - Still crashed ~22% through epoch
   - Hypothesis: Memory pressure or FAISS on CPU instability

### Likely Causes (Ranked)

1. **Primary: Async Mining Race Conditions (80% confidence)**
   - FAISS multiprocessing + PyTorch DataLoader workers = deadlock risk
   - MPS backend may have stricter thread safety requirements
   - Queue starvation symptoms ("output queue empty")
   - Recommendation: Synchronous FAISS queries OR simpler prefetch strategy

2. **Secondary: Memory Leaks (60% confidence)**
   - 771k bank vectors (768D each) = ~600 MB
   - Async queues holding indices + gradients
   - Progressive slowdown before crash
   - Recommendation: Profile memory, reduce prefetch depth

3. **Tertiary: MPS Backend Instability (40% confidence)**
   - All 3 MPS runs failed
   - CPU run also failed (weakens this hypothesis)
   - Recommendation: Try Linux + CUDA for comparison

---

## New PRD: Dual-Path vecRAG + LVM

**Location:** `docs/PRDs/PRD_LVM_plus_vecRAG_Dual_Path_Next_Vector_Generation_System.md`

**Purpose:** Improve Stage-1 recall (currently 0.65% Hit@5) by adding Two-Tower retriever for better query formation.

### Key Design Elements

1. **Two-Tower Retriever**
   - Query tower: GRU/LSTM pooling ‚Üí 768D
   - Doc tower: Identity (use bank vectors as-is)
   - Target: Recall@500 ‚â• 55-60%
   - Training: InfoNCE + curriculum hard negatives

2. **Dual-Path Decision (Per Generation Step)**
   - **SNAP:** cosine ‚â• 0.92 ‚Üí use nearest bank vector (grounded)
   - **NOVEL:** cosine ‚â§ 0.85 ‚Üí use LVM-generated vector (creative)
   - **BLEND:** 0.85 < cosine < 0.92 ‚Üí Œ±-weighted blend

3. **TMD Policy Integration**
   - Legal lane: higher snap threshold (0.94), more grounding
   - Creative lane: lower snap threshold (0.90), more novelty
   - Per-lane thresholds and Œ± schedules

### Alignment with Current Work

‚úÖ **Directly addresses today's training:**
- We're training the Two-Tower retriever (query tower + FAISS)
- Current blocker: Training instability preventing model completion
- Once trained ‚Üí integrate with LVM for dual-path decoding

üìä **Expected Impact:**
- Retriever Recall@500: 55-60% (from ~10% current)
- End-to-end Hit@5: 10-20% (from 0.65% current)
- Novel generation preserved (not forced to snap)

---

## Metrics & Observations

### Training Stability Metrics (All Runs)

| Metric | MPS Simple | MPS Balanced | MPS Final | CPU Test |
|--------|-----------|-------------|-----------|----------|
| Completed Epochs | 0 | 0 | 0 | 0 |
| Max Steps Reached | ? | ? | ~770 | ~1000 |
| Checkpoints Saved | 0 | 0 | 0 | 1 (pre-val) |
| Crash Phase | Training | Training | Training | Training |
| Async Mining Active | Yes | Yes | Yes | No |

### System Resource Patterns

**MPS Final Run (Best Documented):**
- Initial speed: 10.67 it/s (steps 48-50)
- Mid-run speed: 9.68 it/s (steps 298-300)
- Pre-crash speed: 8.31 it/s (step 309) ‚Üí 9.90 it/s (step 380)
- Pattern: Oscillating performance followed by crash
- Queue warnings appeared every ~200 steps

**CPU Test Run:**
- Consistent speed: ~15.8 it/s throughout
- No queue warnings (async mining disabled)
- Still crashed at step ~1000
- Suggests async mining may not be ONLY cause

---

## Comparison to Phase 3 Baselines

### Previous System (LightRAG Reranker)
- ‚úÖ Stable training (no crashes)
- ‚úÖ Completed models available
- ‚ùå Poor Stage-1 recall (~10% for small candidates)
- ‚ùå Query formation not learned (used raw embeddings)

### Current System (Two-Tower v4)
- ‚ùå Unstable training (4/4 crashes)
- ‚ùå No completed models yet
- ‚úÖ Architecture proven in research (dual-encoder retrieval)
- ‚úÖ Curriculum + async mining = better negatives (when stable)

**Action Required:** Stabilize training before quality comparison possible.

---

## Next Steps (Priority Order)

### Immediate (Fix Training Instability)

1. **Disable Async Mining Completely** ‚è±Ô∏è 15 min
   - Run CPU test with synchronous FAISS queries
   - Monitor: Memory usage, training speed, stability
   - Goal: Complete 3 epochs without crash

2. **Reduce Batch Size & Bank Size** ‚è±Ô∏è 10 min
   - Config: Batch 4√ó2=8, 5k bank, 5 epochs
   - Minimal resource pressure test
   - Goal: Identify if memory is the blocker

3. **Add Memory Profiling** ‚è±Ô∏è 20 min
   - Insert: `torch.cuda.memory_summary()` (MPS equiv)
   - Log: RSS memory every 100 steps
   - Goal: Detect leaks before crash

### Short-Term (Restore Training)

4. **Fix Async Mining Architecture** ‚è±Ô∏è 2-4 hours
   - Replace multiprocessing with threading (FAISS thread-safe)
   - Add timeout + fallback to synchronous
   - Implement queue depth limits + backpressure
   - Goal: Stable async mining for MPS

5. **Resume from Checkpoint** ‚è±Ô∏è 30 min
   - Load `epoch_001_pre_validation.pt`
   - Continue CPU training with fixes applied
   - Goal: Validate checkpoint loading works

### Medium-Term (Complete Training)

6. **Full Training Run (Stable Config)** ‚è±Ô∏è 8-12 hours
   - Device: CPU (most stable so far)
   - Config: Batch 8√ó2=16, 10k bank, 30 epochs
   - Async mining: OFF (or fixed version)
   - Goal: First completed Two-Tower model

7. **Evaluate Retrieval Quality** ‚è±Ô∏è 2 hours
   - Metrics: Recall@{10,50,100,500}, Hit@5
   - Compare: vs. Phase-3 baseline (raw GTR-T5)
   - Goal: Validate Recall@500 ‚â• 55% target

### Long-Term (Production Integration)

8. **Implement Dual-Path Decoder** ‚è±Ô∏è 1-2 days
   - Snap/Blend/Novel decision module
   - TMD policy hooks (per-lane thresholds)
   - Telemetry: %SNAP/%BLEND/%NOVEL by lane
   - Goal: Full PRD system operational

9. **Production Hardening** ‚è±Ô∏è 2-3 days
   - Config profiles: Conservative/Neutral/Creative
   - Fallback chains (retriever failure ‚Üí NOVEL)
   - Monitoring dashboards
   - Goal: Ready for Wikipedia ingestion integration

---

## Files Modified Today

### Training Code
- `tools/train_twotower_v4.py` (pre-validation checkpoint added)
- `tools/async_miner.py` (queue health monitoring)

### Launch Scripts
- `launch_v4_mps_simple.sh`
- `launch_v4_mps_balanced.sh`
- `launch_v4_mps_final.sh`
- `launch_v4_cpu_test.sh`

### Documentation
- `docs/PRDs/PRD_LVM_plus_vecRAG_Dual_Path_Next_Vector_Generation_System.md` (NEW)
- `docs/reports/TwoTower_v4_Training_Status_Report_2025-10-22.md` (THIS FILE)

### Training Outputs
- `logs/twotower_v4_mps_simple_20251022_073101.log` (crashed)
- `logs/twotower_v4_mps_balanced_20251022_071717.log` (crashed)
- `logs/twotower_v4_mps_final_20251022_074339.log` (crashed)
- `logs/twotower_v4_cpu_test_20251022_080532.log` (crashed)

### Checkpoints
- `runs/twotower_v4_cpu_test/checkpoints/epoch_001_pre_validation.pt` ‚úÖ (54 MB)

---

## Recommendations

### For Training Stability (Critical)

**Recommendation 1: Synchronous FAISS First**
- Rationale: 4/4 runs failed; async adds complexity
- Action: Complete one full training run without async mining
- Success metric: 30 epochs complete, best.pt created
- Timeline: 8-12 hours (CPU) or 4-6 hours (MPS if stable)

**Recommendation 2: Incremental Complexity**
- Start: No async, small bank (5k), small batch (4√ó2)
- Add: Async mining (simple queue, no TTL)
- Add: Larger bank (50k), curriculum schedule
- Rationale: Isolate failure source
- Timeline: 3-5 training runs over 2-3 days

**Recommendation 3: Platform Testing**
- Test: Same config on Linux + CUDA
- Rationale: MPS backend is newer, may have issues
- Success metric: Compare crash rates MPS vs CUDA
- Timeline: 1 day (if hardware available)

### For PRD Implementation

**Recommendation 4: Parallel Development**
- While fixing training: Implement Dual-Path decoder skeleton
- Use Phase-3 reranker as query tower temporarily
- Test snap/blend/novel logic with existing vectors
- Rationale: Decouple training stability from decoder logic
- Timeline: 1-2 days

**Recommendation 5: Evaluation Framework First**
- Build metrics pipeline: Recall@K, %SNAP/%BLEND/%NOVEL
- Test with dummy retriever (random candidates)
- Rationale: Validate eval before training completes
- Timeline: 4-6 hours

---

## Appendix A: Configuration Comparison

### MPS Final (Most Aggressive)
```yaml
device: mps
batch_size: 16
accumulation_steps: 4
effective_batch: 64
epochs: 30
lr: 5e-5 ‚Üí 1e-6
temperature: 0.05
margin: 0.03
bank_size: 50,000
mining_schedule: "0-5:none;6-10:8@0.82-0.92;11-30:16@0.84-0.96"
async_mining:
  enabled: true
  k: 128
  qbatch: 2048
  ttl: 5
```

### CPU Test (Most Conservative)
```yaml
device: cpu
batch_size: 8
accumulation_steps: 2
effective_batch: 16
epochs: 3
lr: 5e-5 ‚Üí 1e-6
temperature: 0.05
margin: 0.03
bank_size: 10,000
mining_schedule: "0-1:none;2-3:4@0.82-0.92"
async_mining:
  enabled: false  # Disabled for stability
```

---

## Appendix B: Pre-Validation Checkpoint Success

**Code Location:** `tools/train_twotower_v4.py:823-832`

**What We Added (Oct 22, 2025):**
```python
# Save pre-validation checkpoint BEFORE validation runs
pre_val_path = ckpt_dir / f"epoch_{epoch:03d}_pre_validation.pt"
torch.save({
    'epoch': epoch,
    'model_q_state_dict': model_q.state_dict(),
    'model_d_state_dict': model_d.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
    'config': config,
}, pre_val_path)
print(f"üíæ Saved pre-validation checkpoint: {pre_val_path}")
```

**Why This Matters:**
- Previous crashes lost ALL progress (no checkpoint saved)
- Pre-validation checkpoint captures model BEFORE risky validation phase
- Enabled partial recovery even from crashed runs
- **Result:** CPU test crash recovered 22% of epoch 1 progress

**Validation:** ‚úÖ Worked as designed - checkpoint saved, training crashed afterward

---

## Conclusion

**Current Status:** üö® **BLOCKED - Training Instability**

**Core Issue:** Async FAISS mining + PyTorch + MPS/CPU ‚Üí crashes after ~20-35% of first epoch

**Critical Path:**
1. Fix training stability (synchronous FAISS first)
2. Complete one full 30-epoch training run
3. Validate Recall@500 ‚â• 55% (PRD gate)
4. Implement Dual-Path decoder
5. Integrate with Wikipedia ingestion pipeline

**Time Estimate (Critical Path):**
- Training stability fix: 1 day
- First completed model: 1-2 days (including training time)
- Dual-path decoder: 2-3 days
- **Total:** 4-6 days to operational system

**Next Action:** Run synchronous FAISS training (CPU, 30 epochs) to establish baseline stability.

---

**Report Generated:** 2025-10-22 (Autonomous System)
**Review Status:** Pending human review
**Contact:** See CLAUDE.md for system guidance
